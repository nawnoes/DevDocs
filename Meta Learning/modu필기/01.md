## 왜 강화학습을 해야하는가?
single isolated decision에 대해서, sequentail한 decision을 결정하는것이 중요. 

- 로보틱스
- 언어
- 자율주행
- business operations
- finance: 현재 강화학습에서는 책으로도 나와있다.
DQN, A3C 등 많은 방법론을 이용해 트레이딩 쪽에 많은 적용이 되어있다.
    + 매수 또는 매도에서 profit이 좋은 쪽으로 학습
    + 생성된 데이터를 이용해서 강화학습을 적용한다.
- 추천 시스템에 많은 적용.

시퀀셜한 데이터를 기반으로 의사결정을 할때, 인텔리전스가 필요하다.

## plan
- supervised learning: 각각의 데이터가 iid 
- sequential decision making: 현재의 결정이 미래 state에 대한 어떻게 영향을 미치는가
    + Markov property를 가정하여 적용된다고 생각함
    + 성공여부를 판단학기 어려움.. 어떤게 성공한거니?

## Terminology & notation
- $s_t$: state
- $o_t$: observation
- $a_t$: action

- ${\fi}_{\theta}(a_t|o_t)$: policy
- ${\fi}_{\theta}(a_t|s_t)$: policy(fully observed)

## Imitation Learning
강화학습이랑 이미테이션 러닝이랑은 다르다.
리워드를 사용하지 않고, $o_t$와 $a_t$를 통해서 policy를 만드는것이다.
- 데이터가 풍부하고 충분히 괜찮으면, 또는 optimal이면 policy를 잘 학습하게 된다. 
- Compound Error 란?
- 여러종류의 이미테이션 

## Reward Function
리워드가 높다 낮다는 목표를 달성하는데 얼마나 관련있는 정보를 가지는가.. 자율주행에서 빠르고 정확하게 가면 점수가 높지만, 사고가 나면 점수가 낮다..?

## 강화학습의 목표
- Trasactory distribution.
- MDP는 그래프로 표기가 가능하다. 
- state를 모르는데 observation을 가지고 action을 하고, 

## Task란 무엇인가?
### supervised learning
data generation distribution
### Reinforcement learning
stata, action ,s의 확률, s,a일때 s'일 조건부 확률, s,a일때 리워드

### examples task distribution
- 추천시스템에서 태스크를 예로 보임
- 3d로 옷을 입는 것을 시뮬레이션 

### Reinforcement learning에서의 태스크
하나의 MDP로 멀티 태스크를 구성하고, 모든 state, action 

### Multi task reinforcement leaerning의 목적
멀티 태스크들에서 리워드를 구하기 어려운 점이 있다.
- Multi-task RL에서는 $s=(\hat{s}, z_i)$ 
- state를 위와 같이 표기를 하고
- $r(s) = r(\hat{s},s_g) = -d(\hat{s},s_g)$
- goal conditional rl은 하나의 MDP

## anatomy of reinforcement learning

## 목적은 무엇인가?
- policy gradient를 가지고 어떻게 메타러닝을 적용할것인가?
- 비디오늬 태스크는 
- MAML(Model-Agnostic Meta Learning)은 이너루프가 파인튜닝하는rjt
$min_{theta}\sigma{}$